{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f53a90-72c2-4720-be50-4ee9b6ec3079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.4.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.4.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (1.2.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (0.21.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (8.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b49c7f2-cd47-4623-9049-c3c3685d3d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a1de993-2915-4ebe-8e7b-e18ca3609d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a8b9902-81d1-4a6d-9a99-e9bfc9700924",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdataset = load_dataset(\"tdavidson/hate_speech_offensive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb682164-9b0d-4cc3-b681-c87842e506f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['count', 'hate_speech_count', 'offensive_language_count', 'neither_count', 'class', 'tweet'],\n",
       "    num_rows: 24783\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdataset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da68a50-b3ec-4e2f-9a11-c37fb475f610",
   "metadata": {},
   "source": [
    "**Now to convert the the rawdataset to be pandas compatible**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "212a8d8f-99c3-4b9a-89a9-2355730ca37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rawdataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b8db64d-9ee1-4ddd-aa21-b906245a8ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 6 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   count                     24783 non-null  int64 \n",
      " 1   hate_speech_count         24783 non-null  int64 \n",
      " 2   offensive_language_count  24783 non-null  int64 \n",
      " 3   neither_count             24783 non-null  int64 \n",
      " 4   class                     24783 non-null  int64 \n",
      " 5   tweet                     24783 non-null  object\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb00524-0c15-4980-8e5b-c351b6f5791a",
   "metadata": {},
   "source": [
    "**Performing Datacleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96468d57-d488-493d-98f1-836cccfdea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[['tweet', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0404ac4-8a0d-4447-9109-be7882ce46c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   24783 non-null  object\n",
      " 1   class   24783 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 387.4+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b153d006-b93d-4515-bfe6-8dd158fae038",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop_duplicates(subset='tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1dc3afd9-a1dd-4475-a314-d6210ab97339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   24783 non-null  object\n",
      " 1   class   24783 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 387.4+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f9bfdf-1118-482a-862c-d21629f4b95c",
   "metadata": {},
   "source": [
    "For removing spaces from infront or behind of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ccfcc05-2bb1-4e58-b53b-4612edf062bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['tweet'] = dataset['tweet'].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f0e98dd-73b8-4a56-b2b2-aac75b049be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  class\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...      2\n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...      1\n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...      1\n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...      1\n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e94ec2f-374d-49ad-994d-297d082621e3",
   "metadata": {},
   "source": [
    "Dropping empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecad1a94-90ce-421a-ad85-d3986de325ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  class\n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...      2\n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...      1\n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...      1\n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...      1\n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...      1\n",
       "...                                                  ...    ...\n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...      1\n",
       "24779  you've gone and broke the wrong heart baby, an...      2\n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...      1\n",
       "24781              youu got wild bitches tellin you lies      1\n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...      2\n",
       "\n",
       "[24783 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3d4ea56-9fb9-45d6-bfe0-3af3160f74dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>!!!!!!\"@__BrighterDays: I can not just sit up ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>!!!!&amp;#8220;@selfiequeenbri: cause I'm tired of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\" &amp;amp; you might not get ya bitch back &amp;amp; ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\" @rhythmixx_ :hobbies include: fighting Maria...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\" Keeks is a bitch she curves everyone \" lol I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\" Murda Gang bitch its Gang Land \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\" So hoes that smoke are losers ? \" yea ... go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\" bad bitches is the only thing that i like \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\" bitch get up off me \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\" bitch nigga miss me with it \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\" bitch plz whatever \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\" bitch who do you love \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\" bitches get cut off everyday B \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\" black bottle &amp;amp; a bad bitch \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\" broke bitch cant tell me nothing \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\" cancel that bitch like Nino \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\" cant you see these hoes wont change \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\" fuck no that bitch dont even suck dick \" &amp;#1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\" got ya bitch tip toeing on my hardwood floor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\" her pussy lips like Heaven doors \" &amp;#128524;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\" hoe what its hitting for \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\" i met that pussy on Ocean Dr . i gave that p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\" i need a trippy bitch who fuck on Hennessy \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\" i spend my money how i want bitch its my bus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  class\n",
       "0   !!! RT @mayasolovely: As a woman you shouldn't...      2\n",
       "1   !!!!! RT @mleew17: boy dats cold...tyga dwn ba...      1\n",
       "2   !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...      1\n",
       "3   !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...      1\n",
       "4   !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...      1\n",
       "5   !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...      1\n",
       "6   !!!!!!\"@__BrighterDays: I can not just sit up ...      1\n",
       "7   !!!!&#8220;@selfiequeenbri: cause I'm tired of...      1\n",
       "8   \" &amp; you might not get ya bitch back &amp; ...      1\n",
       "9   \" @rhythmixx_ :hobbies include: fighting Maria...      1\n",
       "10  \" Keeks is a bitch she curves everyone \" lol I...      1\n",
       "11                 \" Murda Gang bitch its Gang Land \"      1\n",
       "12  \" So hoes that smoke are losers ? \" yea ... go...      1\n",
       "13      \" bad bitches is the only thing that i like \"      1\n",
       "14                            \" bitch get up off me \"      1\n",
       "15                    \" bitch nigga miss me with it \"      1\n",
       "16                             \" bitch plz whatever \"      1\n",
       "17                          \" bitch who do you love \"      1\n",
       "18                 \" bitches get cut off everyday B \"      1\n",
       "19                 \" black bottle &amp; a bad bitch \"      1\n",
       "20               \" broke bitch cant tell me nothing \"      1\n",
       "21                    \" cancel that bitch like Nino \"      1\n",
       "22            \" cant you see these hoes wont change \"      1\n",
       "23  \" fuck no that bitch dont even suck dick \" &#1...      1\n",
       "24  \" got ya bitch tip toeing on my hardwood floor...      1\n",
       "25     \" her pussy lips like Heaven doors \" &#128524;      1\n",
       "26                       \" hoe what its hitting for \"      1\n",
       "27  \" i met that pussy on Ocean Dr . i gave that p...      1\n",
       "28     \" i need a trippy bitch who fuck on Hennessy \"      1\n",
       "29  \" i spend my money how i want bitch its my bus...      1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74f5f20-4c20-4fc4-903d-73c6684f00e7",
   "metadata": {},
   "source": [
    "**Installing NLTK for extensive text preprocessing and tokenizing and lemetization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb7d592d-ae26-41c4-b99e-5b3ed9b7a2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: click in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.3.1)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 10.0 MB/s  0:00:00\n",
      "Downloading regex-2025.11.3-cp312-cp312-win_amd64.whl (277 kB)\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Installing collected packages: regex, joblib, nltk\n",
      "\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   ---------------------------------------- 3/3 [nltk]\n",
      "\n",
      "Successfully installed joblib-1.5.3 nltk-3.9.2 regex-2025.11.3\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df101c23-22c0-46e8-9a73-2b52f9b17d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\avase\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\avase\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\avase\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\avase\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\avase\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re, html\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5350adc0-5280-4dca-8a60-7203bd391234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3590159-f4fa-42f0-96f7-284c270e4eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(raw_tweet):\n",
    "    text = html.unescape(str(raw_tweet))\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"@\\w*\", \" \", text)      # remove usernames and @\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)   # to remove URLs\n",
    "    text = re.sub(r\"[^a-z ]\", \" \", text)\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = pos_tag(tokens)\n",
    "\n",
    "    clean_tokens = []\n",
    "    for word, tag in tagged:\n",
    "        if word not in stop_words and len(word) > 1:\n",
    "            wn_tag = get_wordnet_pos(tag)\n",
    "            root = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "            clean_tokens.append(root)\n",
    "\n",
    "    return \" \".join(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30615b69-f3f9-4e5d-a479-e88347394b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['processed_text'] = dataset['tweet'].apply(clean_text)\n",
    "dataset = dataset[dataset['processed_text'].str.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8e8c859-f5f8-4f04-bc17-fe3d61d263bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\avase\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a85bd6d-46cb-495e-836c-85cd7fb2d9f0",
   "metadata": {},
   "source": [
    "**Train Test Split and TF- IDF Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9bddcfed-ddce-4373-ba83-c1c651adafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_text = dataset['processed_text'] \n",
    "y = dataset['class']                  \n",
    "#Class 0 for Hate Speech\n",
    "#Class 1 for offensive Language\n",
    "#Class 2 for neither\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(X_text)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b227eb-4358-4ec7-808d-cea61351a46e",
   "metadata": {},
   "source": [
    "**Using SVM model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c77d9484-a7bb-4728-ba80-c9a083c6a395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 0.9138591890256204\n",
      "SVM report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.16      0.26       286\n",
      "           1       0.93      0.97      0.95      3838\n",
      "           2       0.86      0.92      0.89       833\n",
      "\n",
      "    accuracy                           0.91      4957\n",
      "   macro avg       0.80      0.68      0.70      4957\n",
      "weighted avg       0.90      0.91      0.90      4957\n",
      "\n",
      "SVM confusion matrix:\n",
      " [[  47  213   26]\n",
      " [  27 3716   95]\n",
      " [   4   62  767]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM accuracy:\", acc_svm)\n",
    "print(\"SVM report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "print(\"SVM confusion matrix:\\n\", confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db0ac6-50f4-47c7-853b-3faf51f84b4a",
   "metadata": {},
   "source": [
    "**Training Using Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8be1c034-e6c5-4ef8-9c7a-14c93ff4314c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF accuracy: 0.9053863223724027\n",
      "RF report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.17      0.27       286\n",
      "           1       0.93      0.96      0.94      3838\n",
      "           2       0.83      0.90      0.86       833\n",
      "\n",
      "    accuracy                           0.91      4957\n",
      "   macro avg       0.80      0.68      0.69      4957\n",
      "weighted avg       0.89      0.91      0.89      4957\n",
      "\n",
      "RF confusion matrix:\n",
      " [[  50  208   28]\n",
      " [  25 3691  122]\n",
      " [   4   82  747]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"RF accuracy:\", acc_rf)\n",
    "print(\"RF report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"RF confusion matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffb04ca-07f8-43e8-af9d-5773582d569c",
   "metadata": {},
   "source": [
    "**HyperTuning Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20d99fc3-6139-466f-8192-eab79b3f62e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_base = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_jobs=-1   #in order to use all the cores of my CPU\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 400, 600],\n",
    "    'max_depth': [None, 10, 20, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "977f733a-7c71-4c1c-903c-0dc9743ef2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avase\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 600}\n",
      "Best CV accuracy: 0.9038539144471347\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,          \n",
    "    n_jobs=-1,     # for using all CPU cores\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", grid_search.best_params_)\n",
    "print(\"Best CV accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "34289f89-4401-4206-8e09-654ba254dbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned RF test accuracy: 0.9047811176114585\n",
      "Tuned RF report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.16      0.26       286\n",
      "           1       0.93      0.96      0.94      3838\n",
      "           2       0.83      0.89      0.86       833\n",
      "\n",
      "    accuracy                           0.90      4957\n",
      "   macro avg       0.80      0.67      0.69      4957\n",
      "weighted avg       0.89      0.90      0.89      4957\n",
      "\n",
      "Tuned RF confusion matrix:\n",
      " [[  47  211   28]\n",
      " [  24 3695  119]\n",
      " [   4   86  743]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "acc_best_rf = accuracy_score(y_test, y_pred_best_rf)\n",
    "print(\"Tuned RF test accuracy:\", acc_best_rf)\n",
    "print(\"Tuned RF report:\\n\", classification_report(y_test, y_pred_best_rf))\n",
    "print(\"Tuned RF confusion matrix:\\n\", confusion_matrix(y_test, y_pred_best_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c8fa9f-9f9f-4964-bc46-b4bf35e57fcd",
   "metadata": {},
   "source": [
    "**Predictions made by model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "683996c6-c5aa-4d90-9242-58bf82b58ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_map = {\n",
    "    0: \"Hate Speech\",\n",
    "    1: \"Offensive Language\",\n",
    "    2: \"Neither\"\n",
    "}\n",
    "\n",
    "def predict_with_svm(text):\n",
    "    # For Cleaning the Raw text\n",
    "    cleaned = clean_text(text)\n",
    "    # For Vectorization\n",
    "    X_vec = vectorizer.transform([cleaned])\n",
    "    # Predicting Labels\n",
    "    pred_label = svm_model.predict(X_vec)[0]\n",
    "    # Label it to human readable code\n",
    "    return pred_label, label_map[int(pred_label)]\n",
    "\n",
    "def predict_with_rf(text):\n",
    "    cleaned = clean_text(text)\n",
    "    X_vec = vectorizer.transform([cleaned])\n",
    "    pred_label = best_rf.predict(X_vec)[0]\n",
    "    return pred_label, label_map[int(pred_label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3894f4e2-b968-4841-b613-cfe198a25f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: Fortnite is absolutely shit\n",
      "SVM prediction: 1 -> Offensive Language\n",
      "RF prediction: 1 -> Offensive Language\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Fortnite is absolutely shit\"\n",
    "\n",
    "svm_code, svm_label = predict_with_svm(test_text)\n",
    "rf_code, rf_label  = predict_with_rf(test_text)\n",
    "\n",
    "print(\"Input text:\", test_text)\n",
    "print(\"SVM prediction:\", svm_code, \"->\", svm_label)\n",
    "print(\"RF prediction:\", rf_code, \"->\", rf_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a513fe6-0761-434d-b381-2c741dc66c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
